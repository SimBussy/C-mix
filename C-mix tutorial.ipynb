{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# C-mix model tutorial\n",
    "\n",
    "We first import some necessary tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simulation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d263ce8cb447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mQNEM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQNEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mQNEM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCensoredGeomMixtureRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Simon/Dev/cmix/QNEM/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimulation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCensoredGeomMixtureRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simulation'"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects as ro\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "from QNEM.inference import QNEM\n",
    "from QNEM.simulation import CensoredGeomMixtureRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import scale\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Choose parameters ##\n",
    "n_samples = 1000          # number of patients\n",
    "n_features = 100          # number of features\n",
    "nb_active_features = 30   # number of active covariables\n",
    "K = 1.                    # value of the active coefficients \n",
    "gap = .3                  # gap value to create high/low risk groups\n",
    "rho = 0.5                 # coefficient of the toeplitz correlation matrix\n",
    "r_cf = .5                 # confusion factors rate \n",
    "r_c = 0.5                 # censoring rate\n",
    "pi0 = 0.75                # proportion of desired low risk patients rate\n",
    "p0 = .01                  # geometric parameter for low risk patients\n",
    "p1 = 0.5                  # geometric parameter for high risk patients\n",
    "verbose = True            # verbose mode to detail or not ongoing tasks\n",
    "\n",
    "simu = CensoredGeomMixtureRegression(verbose, n_samples, n_features,\n",
    "                                     nb_active_features, K, rho, pi0,\n",
    "                                     gap, r_c, r_cf, p0, p1)\n",
    "X, Y, delta = simu.simulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Assign index for each feature ##\n",
    "features_names = range(X.shape[1]) \n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "## Split data into training and test sets ##\n",
    "test_size = .3  # proportion of data used for testing\n",
    "rs = ShuffleSplit(n_splits=1, test_size=test_size, random_state=0)\n",
    "\n",
    "for train_index, test_index in rs.split(X):\n",
    "    X_test = X[test_index]\n",
    "    delta_test = delta[test_index]\n",
    "    Y_test = Y[test_index]\n",
    "\n",
    "    X = X[train_index]\n",
    "    Y = Y[train_index]\n",
    "    delta = delta[train_index]  \n",
    "    \n",
    "print(\"%d%% for training, %d%% for testing.\" \n",
    "      % ((1 - test_size) * 100, test_size * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Choose parameters ##\n",
    "tol = 1e-6            # tolerance for the convergence stopping criterion \n",
    "eta = 0.3             # parameter controlling the trade-off between l1 \n",
    "                      # and l2 regularization in the elasticNet\n",
    "fit_intercept = True  # whether or not an intercept term is fitted\n",
    "gamma_chosen ='1se'   # way to select l_elasticNet_chosen: '1se' or 'min'\n",
    "warm_start = True     # at each L-BGFS-B iteration, reset beta to 0 or take \n",
    "                      # the previous value \n",
    "grid_size = 30        # grid size for the cross validation procedure\n",
    "metric = 'C-index'    # cross-validation metric: 'log_lik' or 'C-index'\n",
    "verbose = True \n",
    "\n",
    "## Choose between C-mix or CURE model ##\n",
    "model = \"C-mix\"  # \"C-mix\", \"CURE\"       \n",
    "\n",
    "if verbose:\n",
    "    print(\"\\nLaunching %s...\\n\" % model)\n",
    "\n",
    "learner = QNEM(l_elastic_net=0., eta=eta, max_iter=100, tol=tol, \n",
    "               warm_start=warm_start, verbose=verbose, model=model, \n",
    "               fit_intercept=fit_intercept)\n",
    "learner.n_features = n_features         \n",
    "\n",
    "## Cross-validation ##\n",
    "learner.cross_validate(X, Y, delta, n_folds=5, verbose=False, eta=eta, \n",
    "                       grid_size=grid_size, metric=metric)\n",
    "avg_scores = learner.scores.mean(axis=1)\n",
    "l_elastic_net_best = learner.l_elastic_net_best\n",
    "if gamma_chosen == '1se':\n",
    "    l_elastic_net_chosen = learner.l_elastic_net_chosen\n",
    "if gamma_chosen == 'min':\n",
    "    l_elastic_net_chosen = l_elastic_net_best\n",
    "    \n",
    "grid_elastic_net = learner.grid_elastic_net # get the cross-validation grid \n",
    "                                            # to plot learning curves\n",
    "\n",
    "## Run selected model with l_elasticNet_chosen ##\n",
    "learner = QNEM(l_elastic_net=l_elastic_net_chosen, eta=eta, tol=tol,\n",
    "               warm_start=warm_start, verbose=verbose, model=model,\n",
    "               fit_intercept=fit_intercept)\n",
    "learner.n_features = n_features\n",
    "learner.fit(X, Y, delta)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Obtain the marker vector on test set ##\n",
    "coeffs = learner.coeffs\n",
    "marker = QNEM.predict_proba(X_test, fit_intercept, coeffs) \n",
    "c_index = QNEM._c_index(Y_test, delta_test, marker)\n",
    "\n",
    "print(\"Done predicting on test set.\")\n",
    "print(\"C-index : %.2f\" % c_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Display learning curves ##\n",
    "score_test = []\n",
    "for idx_elastic_net, l_elastic_net in enumerate(grid_elastic_net):\n",
    "    learner_ = QNEM(verbose=False, l_elastic_net=l_elastic_net,\n",
    "                    eta=eta, warm_start=warm_start, tol=tol, model=model,\n",
    "                    fit_intercept=fit_intercept)\n",
    "    learner_.n_features = n_features\n",
    "    learner_.fit(X, Y, delta)\n",
    "    if metric == 'log_lik':\n",
    "        pc_ = 1. / np.mean(T[delta == 0])\n",
    "        score_ = learner_._log_lik(X_test, Y_test, delta_test)              \n",
    "    if metric == 'C-index':\n",
    "        marker_ = QNEM.predict_proba(X_test, fit_intercept, learner_.coeffs)\n",
    "        score_ = QNEM._c_index(Y_test, delta_test, marker_) \n",
    "    score_test.append(score_)\n",
    "\n",
    "fig = pl.figure(figsize = (10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(grid_elastic_net, avg_scores, label=metric + ' on test (CV)')\n",
    "pl.xscale('log')\n",
    "ax.plot(grid_elastic_net, score_test, '-r', label=metric + ' on validation')\n",
    "y_min, y_max = ax.get_ylim()\n",
    "ax.set_ylim([y_min, y_max])\n",
    "ax.plot(l_elastic_net_best, y_min, 'g^', ms=20, label='best gamma CV')\n",
    "ax.plot(l_elastic_net_chosen, y_min, 'r^', ms=20, label='gamma chosen')\n",
    "pl.title(\"Learning curves (%s)\" % model, fontsize=20)\n",
    "pl.xlabel('gamma', fontsize=15)\n",
    "pl.ylabel(metric, fontsize=15)\n",
    "pl.legend(bbox_to_anchor=(1.05, 1), loc=2,borderaxespad=0., \n",
    "          numpoints=1, markerscale=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10, 6))\n",
    "pl.title(\"Objectif convergence %s\" % model, fontsize=20)\n",
    "pl.xlabel('QNEM iterations', fontsize=15)\n",
    "pl.ylabel('Objectif', fontsize=15)\n",
    "pl.plot(learner.get_history(\"n_iter\"), learner.get_history(\"obj\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## True beta ##\n",
    "beta = np.zeros(n_features)\n",
    "beta[0:nb_active_features] = K\n",
    "fig = pl.figure(figsize=(15, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.stem(beta)\n",
    "ax1.set_xlim([-5, len(beta) + 5])\n",
    "ax1.set_title(\"True beta\", fontsize=20)\n",
    "pl.xlabel('Values', fontsize=15)\n",
    "pl.ylabel('Coefficients', fontsize=15)\n",
    "\n",
    "## Beta estimate ##\n",
    "if fit_intercept:\n",
    "    coeffs = coeffs[1:]\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.stem(coeffs)\n",
    "cf_end = nb_active_features + int((n_features-nb_active_features) * r_cf)\n",
    "coeffs_cf = coeffs[nb_active_features:cf_end]\n",
    "coeffs_cf = np.append(np.repeat([np.nan], nb_active_features), coeffs_cf)\n",
    "ax2.stem(coeffs_cf, linefmt='m-', markerfmt='mo', label='confusion factors')\n",
    "ax2.set_xlim([-5, len(coeffs) + 5])\n",
    "ax2.set_title(\"Beta estimate (%s)\" % model, fontsize=20)\n",
    "pl.xlabel('Values', fontsize=15)\n",
    "pl.ylabel('Coefficients', fontsize=15)\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC(t) curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get T quantiles for AUC(t) ##\n",
    "nb_t = 14 # desired number of quantiles\n",
    "timesAUC = pd.DataFrame(Y).quantile(\n",
    "            q = (1. / nb_t + np.linspace(0, 1, nb_t,endpoint=False))[1:-1]\n",
    "                                    ).drop_duplicates().as_matrix()      \n",
    "\n",
    "ro.globalenv['Y_test'] = Y_test\n",
    "ro.globalenv['delta_test'] = delta_test\n",
    "ro.globalenv['marker'] = marker\n",
    "ro.globalenv['timesAUC'] = timesAUC\n",
    "ro.r('library(timeROC)')\n",
    "ro.r('auc_t = timeROC(Y_test, delta_test, marker, cause=1, times=timesAUC)')\n",
    "auc_t = ro.r('auc_t$AUC')\n",
    "\n",
    "fig = pl.figure(figsize=(10, 6)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.tick_params(labelsize=15)\n",
    "pl.title(\"AUC(t) Curve\", fontsize=20)\n",
    "pl.xlabel('Days', fontsize=15)\n",
    "pl.ylabel('AUC', fontsize=15)\n",
    "ax.plot(timesAUC, auc_t, '-r', label=model)\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
